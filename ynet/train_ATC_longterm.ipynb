{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "determined-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import argparse\n",
    "import torch\n",
    "from model import YNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "finished-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4fc1d7",
   "metadata": {},
   "source": [
    "#### Some hyperparameters and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "arabic-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = 'config/atc_5_30.yaml'  # yaml config file containing all the hyperparameters\n",
    "EXPERIMENT_NAME = 'atc_5_30'  # arbitrary name for this experiment\n",
    "DATASET_NAME = 'atc'\n",
    "\n",
    "TRAIN_DATA_PATH = 'data/ATC/atc_train_5_30.pkl'\n",
    "TRAIN_IMAGE_PATH = 'data/ATC/train'\n",
    "VAL_DATA_PATH = 'data/ATC/atc_test_5_30.pkl'\n",
    "VAL_IMAGE_PATH = 'data/ATC/test'\n",
    "OBS_LEN = 5  # in timesteps\n",
    "PRED_LEN = 30  # in timesteps\n",
    "NUM_GOALS = 20  # K_e\n",
    "NUM_TRAJ = 1  # K_a\n",
    "\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe74062c",
   "metadata": {},
   "source": [
    "#### Load config file and print hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dangerous-cutting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resize': 0.055,\n",
       " 'batch_size': 8,\n",
       " 'viz_epoch': 10,\n",
       " 'learning_rate': 0.0001,\n",
       " 'num_epochs': 100,\n",
       " 'encoder_channels': [32, 32, 64, 64, 64],\n",
       " 'decoder_channels': [64, 64, 64, 32, 32],\n",
       " 'waypoints': [14, 29],\n",
       " 'temperature': 1.8,\n",
       " 'segmentation_model_fp': 'segmentation_models/SDD_segmentation.pth',\n",
       " 'semantic_classes': 2,\n",
       " 'loss_scale': 1000,\n",
       " 'kernlen': 31,\n",
       " 'nsig': 4,\n",
       " 'use_features_only': False,\n",
       " 'unfreeze': 100,\n",
       " 'use_TTST': True,\n",
       " 'rel_threshold': 0.002,\n",
       " 'use_CWS': True,\n",
       " 'CWS_params': {'sigma_factor': 6, 'ratio': 2, 'rot': True}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(CONFIG_FILE_PATH) as file:\n",
    "    params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "experiment_name = CONFIG_FILE_PATH.split('.yaml')[0].split('config/')[1]\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-pressure",
   "metadata": {},
   "source": [
    "#### Load preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "german-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(TRAIN_DATA_PATH)\n",
    "df_val = pd.read_pickle(VAL_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "corporate-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackId</th>\n",
       "      <th>frame</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>sceneId</th>\n",
       "      <th>metaId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15163400</td>\n",
       "      <td>450915</td>\n",
       "      <td>8247.2</td>\n",
       "      <td>5118.0</td>\n",
       "      <td>scene</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15163400</td>\n",
       "      <td>450930</td>\n",
       "      <td>8264.7</td>\n",
       "      <td>5114.0</td>\n",
       "      <td>scene</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15163400</td>\n",
       "      <td>450945</td>\n",
       "      <td>8253.1</td>\n",
       "      <td>5115.8</td>\n",
       "      <td>scene</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15163400</td>\n",
       "      <td>450960</td>\n",
       "      <td>8264.2</td>\n",
       "      <td>5129.0</td>\n",
       "      <td>scene</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15163400</td>\n",
       "      <td>450975</td>\n",
       "      <td>8247.3</td>\n",
       "      <td>5109.3</td>\n",
       "      <td>scene</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trackId   frame       x       y sceneId  metaId\n",
       "0  15163400  450915  8247.2  5118.0   scene       0\n",
       "1  15163400  450930  8264.7  5114.0   scene       0\n",
       "2  15163400  450945  8253.1  5115.8   scene       0\n",
       "3  15163400  450960  8264.2  5129.0   scene       0\n",
       "4  15163400  450975  8247.3  5109.3   scene       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ade5e2",
   "metadata": {},
   "source": [
    "#### Initiate model and load pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "harmful-colleague",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/ynet-env/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'segmentation_models_pytorch.unet.model.Unet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/anaconda3/envs/ynet-env/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'segmentation_models_pytorch.encoders.resnet.ResNetEncoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/anaconda3/envs/ynet-env/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/anaconda3/envs/ynet-env/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/anaconda3/envs/ynet-env/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/anaconda3/envs/ynet-env/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/anaconda3/envs/ynet-env/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/anaconda3/envs/ynet-env/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torchvision.models.resnet.Bottleneck' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/anaconda3/envs/ynet-env/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Identity' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/anaconda3/envs/ynet-env/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/anaconda3/envs/ynet-env/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'segmentation_models_pytorch.base.modules.Activation' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/anaconda3/envs/ynet-env/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Softmax' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "model = YNet(obs_len=OBS_LEN, pred_len=PRED_LEN, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a2a2c",
   "metadata": {},
   "source": [
    "#### Start training\n",
    "Note, the Val ADE and FDE are without TTST and CWS to save time. Therefore, the numbers will be worse than the final values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "optional-colleague",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prepare Dataset: 100%|██████████| 8/8 [00:00<00:00, 157.46it/s]\n",
      "Prepare Dataset: 100%|██████████| 1/1 [00:00<00:00, 153.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/28/_2zwxp6x40bft_sx5lsvs6jr0000gn/T/ipykernel_40071/2964958661.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.train(df_train, df_val, params, train_image_path=TRAIN_IMAGE_PATH, val_image_path=VAL_IMAGE_PATH,\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEXPERIMENT_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_goals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_GOALS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_traj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_TRAJ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             device=None, dataset_name=DATASET_NAME)\n",
      "\u001b[0;32m~/Documents/project/TrajectoryPrediction/Human-Path-Prediction/ynet/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, val_data, params, train_image_path, val_image_path, experiment_name, batch_size, num_goals, num_traj, device, dataset_name)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m \t\t\ttrain_ADE, train_FDE, train_loss = train(model, train_loader, train_images, e, obs_len, pred_len,\n\u001b[0m\u001b[1;32m    325\u001b[0m                                                                                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \t\t\t\t\t\t\t\t\t\t\t\t\t input_template, optimizer, criterion, dataset_name, self.homo_mat)\n",
      "\u001b[0;32m~/Documents/project/TrajectoryPrediction/Human-Path-Prediction/ynet/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, train_images, e, obs_len, pred_len, batch_size, params, gt_template, device, input_template, optimizer, criterion, dataset_name, homo_mat)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unfreeze'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# before unfreeze only need to do semantic segmentation once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                         \u001b[0mscene_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                         \u001b[0mscene_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "model.train(df_train, df_val, params, train_image_path=TRAIN_IMAGE_PATH, val_image_path=VAL_IMAGE_PATH,\n",
    "            experiment_name=EXPERIMENT_NAME, batch_size=BATCH_SIZE, num_goals=NUM_GOALS, num_traj=NUM_TRAJ, \n",
    "            device=None, dataset_name=DATASET_NAME)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ada0c2da736d1786dae0b861f2e656eb41ef26679ec6a6fa084ad2d1d109ad9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ynet-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
